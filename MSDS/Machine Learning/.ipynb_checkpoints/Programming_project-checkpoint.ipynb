{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "fdcf8421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the training data \n",
    "#And storing the unique words in dictionary along with its frequency\n",
    "N = 640000\n",
    "N1 = 160000\n",
    "N2 = 40000\n",
    "N3 = 10000\n",
    "N4 = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2691777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2fd4b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_file = open(\"training_data.txt\", \"r\").read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "07306163",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_file1 = []\n",
    "tr_file2 = []\n",
    "tr_file3 = []\n",
    "tr_file4 = []\n",
    "tr_file1 = tr_file[0:160000]\n",
    "tr_file2 = tr_file[0:40000]\n",
    "tr_file3 = tr_file[0:10000]\n",
    "tr_file4 = tr_file[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "eff90049",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in tr_file:\n",
    "    if i in d:\n",
    "        d[i] = d[i]+1\n",
    "    else:\n",
    "        d[i] = 1\n",
    "#for key in list(d.keys()):\n",
    " #   print(key, \":\", d[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "8b564ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {}\n",
    "for i in tr_file1:\n",
    "    if i in d1:\n",
    "        d1[i] = d1[i]+1\n",
    "    else:\n",
    "        d1[i] = 1\n",
    "#for key in list(d1.keys()):\n",
    "#    print(key, \":\", d1[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "12936243",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = {}\n",
    "for i in tr_file2:\n",
    "    if i in d2:\n",
    "        d2[i] = d2[i]+1\n",
    "    else:\n",
    "        d2[i] = 1\n",
    "#for key in list(d2.keys()):\n",
    " #   print(key, \":\", d2[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e14c0d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "d3 = {}\n",
    "for i in tr_file3:\n",
    "    if i in d3:\n",
    "        d3[i] = d3[i]+1\n",
    "    else:\n",
    "        d3[i] = 1\n",
    "#for key in list(d3.keys()):\n",
    " #   print(key, \":\", d3[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6a5e1094",
   "metadata": {},
   "outputs": [],
   "source": [
    "d4 = {}\n",
    "for i in tr_file4:\n",
    "    if i in d4:\n",
    "        d4[i] = d4[i]+1\n",
    "    else:\n",
    "        d4[i] = 1\n",
    "#for key in list(d4.keys()):\n",
    " #   print(key, \":\", d4[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adf32aa",
   "metadata": {},
   "source": [
    "## MLE Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e0a22dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLE models\n",
    "\n",
    "mle = dict()\n",
    "for word in list(d.keys()):\n",
    "    mle[word] = d[word]/N\n",
    "#for i in list(mle.keys()):\n",
    "#    print(i, \":\", mle[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "01591be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mle1 = dict()\n",
    "for word in list(d1.keys()):\n",
    "    mle1[word] = d1[word]/N1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "3f7eebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mle2 = dict()\n",
    "for word in list(d2.keys()):\n",
    "    mle2[word] = d2[word]/N2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "ef41c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mle3 = dict()\n",
    "for word in list(d3.keys()):\n",
    "    mle3[word] = d3[word]/N3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "791e73e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mle4 = dict()\n",
    "for word in list(d4.keys()):\n",
    "    mle4[word] = d4[word]/N4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f3b4fb",
   "metadata": {},
   "source": [
    "## MAP Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "efdc9f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAP model\n",
    "\n",
    "ma = dict()\n",
    "for word in list(d.keys()):\n",
    "    ma[word] = (d[word]+2-1)/(N+20000-10000)\n",
    "#for i in list(ma.keys()):\n",
    "#    print(i, \":\", ma[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "5ab889b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma1 = dict()\n",
    "for word in list(d1.keys()):\n",
    "    ma1[word] = (d1[word]+2-1)/(N1+20000-10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9313b66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma2 = dict()\n",
    "for word in list(d2.keys()):\n",
    "    ma2[word] = (d2[word]+2-1)/(N2+20000-10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "25535283",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma3 = dict()\n",
    "for word in list(d3.keys()):\n",
    "    ma3[word] = (d3[word]+2-1)/(N3+20000-10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "90cd94b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma4 = dict()\n",
    "for word in list(d4.keys()):\n",
    "    ma4[word] = (d4[word]+2-1)/(N4+20000-10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99561a4a",
   "metadata": {},
   "source": [
    "## Predictive distribution models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "d31b98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictive distribution model\n",
    "\n",
    "pd = dict()\n",
    "for word in list(d.keys()):\n",
    "    pd[word] = (d[word]+2)/(N+20000)\n",
    "#for i in list(pd.keys()):\n",
    "#    print(i, \":\", pd[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "7c6fc1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1 = dict()\n",
    "for word in list(d1.keys()):\n",
    "    pd1[word] = (d1[word]+2)/(N1+20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ac071bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2 = dict()\n",
    "for word in list(d2.keys()):\n",
    "    pd2[word] = (d2[word]+2)/(N2+20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "99efd12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd3 = dict()\n",
    "for word in list(d3.keys()):\n",
    "    pd3[word] = (d3[word]+2)/(N3+20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ca7bff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd4 = dict()\n",
    "for word in list(d4.keys()):\n",
    "    pd4[word] = (d4[word]+2)/(N4+20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a744ebe4",
   "metadata": {},
   "source": [
    "## Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "7edc770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perplexity \n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "707fb608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(model, file):\n",
    "    p = 0\n",
    "    for i in file:\n",
    "        p += np.log(model[i])\n",
    "    perplexity = math.exp(-p/len(file))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d704882",
   "metadata": {},
   "source": [
    "## Perplexities of training models of different size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "cc3f3f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity on train set of MLE model of size N, N/4, N/16, N/64, N/128 is: \n",
      "8506.43367662384 8292.385691215124 7478.035656314462 5005.389219343304 3388.2567752667333\n"
     ]
    }
   ],
   "source": [
    "print(\"The perplexity on train set of MLE model of size N, N/4, N/16, N/64, N/128 is: \")\n",
    "print(perplexity(mle, tr_file), perplexity(mle1, tr_file1), perplexity(mle2, tr_file2), perplexity(mle3, tr_file3), perplexity(mle4, tr_file4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "b216c109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity on train set of MAP model of size N, N/4, N/16, N/64, N/128 is: \n",
      "8506.96513236839 8303.124332848962 7669.433287645091 6453.994771744834 5915.104263875246\n"
     ]
    }
   ],
   "source": [
    "print(\"The perplexity on train set of MAP model of size N, N/4, N/16, N/64, N/128 is: \")\n",
    "print(perplexity(ma, tr_file), perplexity(ma1, tr_file1), perplexity(ma2, tr_file2), perplexity(ma3, tr_file3), perplexity(ma4, tr_file4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "2bc313a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity on train set of predictive distribution model of size N, N/4, N/16, N/64, N/128 is: \n",
      "8508.427803625034 8324.246394665119 7866.496544080013 7230.294305050776 7014.415012644821\n"
     ]
    }
   ],
   "source": [
    "print(\"The perplexity on train set of predictive distribution model of size N, N/4, N/16, N/64, N/128 is: \")\n",
    "print(perplexity(pd, tr_file), perplexity(pd1, tr_file1), perplexity(pd2, tr_file2), perplexity(pd3, tr_file3), perplexity(pd4, tr_file4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31846072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "886c8c53",
   "metadata": {},
   "source": [
    "## Test Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "6082a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction of test data with our 3 models\n",
    "#first we read the test data\n",
    "test_file = open(\"test_data.txt\", \"r\").read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "5145af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = {}\n",
    "for i in test_file:\n",
    "    if i in dtest:\n",
    "        dtest[i] = dtest[i]+1\n",
    "    else:\n",
    "        dtest[i] = 1\n",
    "#for key in list(dtest.keys()):\n",
    "#    print(key, \":\", dtest[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ea9bb",
   "metadata": {},
   "source": [
    "## Testing the three trained models of different sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3484ad",
   "metadata": {},
   "source": [
    "## MLE Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "2298f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mle_pred = dict()\n",
    "for word in list(dtest.keys()):\n",
    "    if(word in mle.keys()):\n",
    "        mle_pred[word] = mle[word]\n",
    "    else:\n",
    "        mle_pred[word] = (0/N)\n",
    "#for i in list(mle_pred.keys()):\n",
    "#    print(i, \":\", mle_pred[i])\n",
    "\n",
    "mle_pred1 = dict()\n",
    "for word in list(dtest.keys()):\n",
    "    if(word in mle1.keys()):\n",
    "        mle_pred1[word] = mle1[word]\n",
    "    else:\n",
    "        mle_pred1[word] = (0/N1)\n",
    "        \n",
    "mle_pred2 = dict()\n",
    "for word in list(dtest.keys()):\n",
    "    if(word in mle2.keys()):\n",
    "        mle_pred2[word] = mle2[word]\n",
    "    else:\n",
    "        mle_pred2[word] = (0/N2)\n",
    "        \n",
    "mle_pred3 = dict()\n",
    "for word in list(dtest.keys()):\n",
    "    if(word in mle3.keys()):\n",
    "        mle_pred3[word] = mle3[word]\n",
    "    else:\n",
    "        mle_pred3[word] = (0/N3)\n",
    "        \n",
    "mle_pred4 = dict()\n",
    "for word in list(dtest.keys()):\n",
    "    if(word in mle4.keys()):\n",
    "        mle_pred4[word] = mle4[word]\n",
    "    else:\n",
    "        mle_pred4[word] = (0/N4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "fb7cad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in list(mle_pred4.keys()):\n",
    "#    if mle_pred4[i] == 0.0:\n",
    "#        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1778dbce",
   "metadata": {},
   "source": [
    "## MAP Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "6ab5ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_pred = dict()\n",
    "for word in list(dtest.keys()):\n",
    "    if(word in ma.keys()):\n",
    "        map_pred[word] = ma[word]\n",
    "    else:\n",
    "        map_pred[word] = (0+2-1)/(N+20000-10000)\n",
    "#for i in list(map_pred.keys()):\n",
    " #   print(i, \":\", map_pred[i])\n",
    "\n",
    "map_pred1 = dict()\n",
    "for word in list(dtest.keys()):\n",
    "    if(word in ma1.keys()):\n",
    "        map_pred1[word] = ma1[word]\n",
    "    else:\n",
    "        map_pred1[word] = (0+2-1)/(N1+20000-10000)\n",
    "\n",
    "map_pred2 = dict()\n",
    "for word in list(dtest.keys()):\n",
    "    if(word in ma2.keys()):\n",
    "        map_pred2[word] = ma2[word]\n",
    "    else:\n",
    "        map_pred2[word] = (0+2-1)/(N2+20000-10000)\n",
    "\n",
    "map_pred3 = dict()\n",
    "for word in list(dtest.keys()):\n",
    "    if(word in ma3.keys()):\n",
    "        map_pred3[word] = ma3[word]\n",
    "    else:\n",
    "        map_pred3[word] = (0+2-1)/(N3+20000-10000)\n",
    "\n",
    "map_pred4 = dict()\n",
    "for word in list(dtest.keys()):\n",
    "    if(word in ma4.keys()):\n",
    "        map_pred4[word] = ma4[word]\n",
    "    else:\n",
    "        map_pred4[word] = (0+2-1)/(N4+20000-10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d963f6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3af2e1f",
   "metadata": {},
   "source": [
    "## Predictive distribution prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "2b720670",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_pred = dict()\n",
    "for word in list(dtest.keys()):\n",
    "    if(word in pd.keys()):\n",
    "        pd_pred[word] = pd[word]\n",
    "    else:\n",
    "        pd_pred[word] = (0+2)/(N+20000)\n",
    "#for i in list(map_pred.keys()):\n",
    " #   print(i, \":\", map_pred[i])\n",
    "\n",
    "pd_pred1 = dict()\n",
    "for word in list(dtest.keys()):\n",
    "    if(word in pd1.keys()):\n",
    "        pd_pred1[word] = pd1[word]\n",
    "    else:\n",
    "        pd_pred1[word] = (0+2)/(N1+20000)\n",
    "        \n",
    "pd_pred2 = dict()\n",
    "for word in list(dtest.keys()):\n",
    "    if(word in pd2.keys()):\n",
    "        pd_pred2[word] = pd2[word]\n",
    "    else:\n",
    "        pd_pred2[word] = (0+2)/(N2+20000)\n",
    "        \n",
    "pd_pred3 = dict()\n",
    "for word in list(dtest.keys()):\n",
    "    if(word in pd3.keys()):\n",
    "        pd_pred3[word] = pd3[word]\n",
    "    else:\n",
    "        pd_pred3[word] = (0+2)/(N3+20000)\n",
    "        \n",
    "pd_pred4 = dict()\n",
    "for word in list(dtest.keys()):\n",
    "    if(word in pd4.keys()):\n",
    "        pd_pred4[word] = pd4[word]\n",
    "    else:\n",
    "        pd_pred4[word] = (0+2)/(N4+20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba7b811",
   "metadata": {},
   "source": [
    "## Perplexities of all the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "e2a53585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity on test set of MLE model of size N, N/4, N/16, N/64, N/128 is: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-289-014082a027dd>:4: RuntimeWarning: divide by zero encountered in log\n",
      "  p += np.log(model[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8657.623041731129 inf inf inf inf\n"
     ]
    }
   ],
   "source": [
    "print(\"The perplexity on test set of MLE model of size N, N/4, N/16, N/64, N/128 is: \")\n",
    "print(perplexity(mle_pred, test_file), perplexity(mle_pred1, test_file), perplexity(mle_pred2, test_file), perplexity(mle_pred3, test_file), perplexity(mle_pred4, test_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "1fa73911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity on test set of MAP model of size N, N/4, N/16, N/64, N/128 is: \n",
      "8654.590090965366 8839.546029448937 9380.752312326787 9992.362371992125 10098.36492411617\n"
     ]
    }
   ],
   "source": [
    "print(\"The perplexity on test set of MAP model of size N, N/4, N/16, N/64, N/128 is: \")\n",
    "print(perplexity(map_pred, test_file), perplexity(map_pred1, test_file), perplexity(map_pred2, test_file), perplexity(map_pred3, test_file), perplexity(map_pred4, test_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "fec0ba28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity on test set of predictive distribution model of size N, N/4, N/16, N/64, N/128 is: \n",
      "8652.803792634657 8817.904839672385 9224.511912933269 9668.062580182157 9814.024919445475\n"
     ]
    }
   ],
   "source": [
    "print(\"The perplexity on test set of predictive distribution model of size N, N/4, N/16, N/64, N/128 is: \")\n",
    "print(perplexity(pd_pred, test_file), perplexity(pd_pred1, test_file), perplexity(pd_pred2, test_file), perplexity(pd_pred3, test_file), perplexity(pd_pred4, test_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "6c32a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab9c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662bc806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "70b98a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [N,N1,N2,N3,N4]\n",
    "y1 = [perplexity(mle, tr_file), perplexity(mle1, tr_file1), perplexity(mle2, tr_file2), perplexity(mle3, tr_file3), perplexity(mle4, tr_file4)]\n",
    "y2 = [perplexity(ma, tr_file), perplexity(ma1, tr_file1), perplexity(ma2, tr_file2), perplexity(ma3, tr_file3), perplexity(ma4, tr_file4)]\n",
    "y3 = [perplexity(pd, tr_file), perplexity(pd1, tr_file1), perplexity(pd2, tr_file2), perplexity(pd3, tr_file3), perplexity(pd4, tr_file4)]\n",
    "\n",
    "y4 = [perplexity(mle_pred, test_file), 1000000000, 1000000000,  1000000000, 1000000000]\n",
    "y5 = [perplexity(map_pred, test_file), perplexity(map_pred1, test_file), perplexity(map_pred2, test_file), perplexity(map_pred3, test_file), perplexity(map_pred4, test_file)]\n",
    "y6 = [perplexity(pd_pred, test_file), perplexity(pd_pred1, test_file), perplexity(pd_pred2, test_file), perplexity(pd_pred3, test_file), perplexity(pd_pred4, test_file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604ba444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86ae40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225784e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
